{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "* [Introduction](#Introduction)\n",
    "* [Installation](#Installation)\n",
    "* [Prover](#Prover)\n",
    "    * [Prover Class]()\n",
    "    * [Custom Constructor]()\n",
    "    * [Single-Task Prover]()\n",
    "* [Selection Strategies](#Selection-Strategies)\n",
    "    * [Predictions Class](#Attributes)\n",
    "    * [Goal Embedding](#Goal-Embedding)\n",
    "    * [Theorem Embedding](#Theorem-Embedding)\n",
    "    * [Proof State Search](#Proof-State)\n",
    "    * [Proof State Embedding](#Proof-State-Embedding)\n",
    "    * [Proof State Encoding](#Proof-State-Encoding)\n",
    "    * [Tactic Selection](#Tactic-Selection)\n",
    "    * [Premise Selection](#Premise-Selection)\n",
    "* [Related Work](#Related-Work)  \n",
    "\n",
    "[Run](#Run-DeepHol)\n",
    "\n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction  \n",
    "\n",
    "## How to Use This Notebook  \n",
    "First, follow the instructions below to install deephol in the same directory as this notebook.  \n",
    "\n",
    "By reading through the rest of the documentation, you will be able to implement your own theorem prover via this notebook.  \n",
    "\n",
    "Within this documentation are code cells where you can implement your own functions. Once you write the function, run the cell to overwrite it. You can also choose to leave them blank and deephol will fall back on default behavior.  \n",
    "\n",
    "Use the [cell](#Run-DeepHol) at the bottom to run DeepHOL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation\n",
    "## Basic Dependencies\n",
    "* Anaconda Python\n",
    "* gcc\n",
    "* g++\n",
    "* Docker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building from source\n",
    "Follow this guide if you want to build on your local machine without using the container.\n",
    "\n",
    "## Setting up your virtual environment\n",
    "Create and activate a conda environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "conda create --name deephol\n",
    "conda activate deephol\n",
    "pip install h5py six numpy scipy wheel mock pyfarmhash grpcio\n",
    "pip install keras_applications==1.0.6 keras_preprocessing==1.0.5 --no-deps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clone the deepmath repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Update this Repository to include the HolJup files\n",
    "!git clone https://github.com/tensorflow/deepmath.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Bazel\n",
    "Bazel is a build manager for tensorflow. We need to install this in order to build deepmath."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "wget https://github.com/bazelbuild/bazel/releases/download/0.21.0/bazel-0.21.0-installer-linux-x86_64.sh\n",
    "chmod 777 bazel-0.21.0-installer-linux-x86_64.sh\n",
    "bash bazel-0.21.0-installer-linux-x86_64.sh --prefix=$HOME/bazel\n",
    "PATH=$HOME/bazel/bin:$PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure tensorflow\n",
    "Navigate to the tensorflow dirctory and configure the following options. You can make changes here depending on your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd deepmath/tensorflow\n",
    "TF_IGNORE_MAX_BAZEL_VERSION=1   TF_NEED_OPENCL_SYCL=0   TF_NEED_COMPUTECPP=1   TF_NEED_ROCM=0   TF_NEED_CUDA=0   TF_ENABLE_XLA=0   TF_DOWNLOAD_CLANG=0   TF_NEED_MPI=0   TF_SET_ANDROID_WORKSPACE=0 CC_OPT_FLAGS=\"-march=native -Wno-sign-compare\"  ./configure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow will ask you to specify a python path. It will also give you a default option. Select the default and take note of the path it gives you.  \n",
    "Now set the environment variable to that value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export $PYTHON_BIN_PATH=<path given by tensorflow>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build tensorflow with Bazel\n",
    "\n",
    "This step will take awhile. go fix yourself some snacks while it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd ..\n",
    "bazel build -c opt //deepmath/deephol:main --define grpc_no_ares=true --python_path=$PYTHON_BIN_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run deephol\n",
    "### Download and Setup HOL-Light container\n",
    "Create a docker network with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker network create holist_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the HOL-Light image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run -d --network=holist_net --name=holist gcr.io/deepmath/hol-light"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can get the ip of the HOL-Light image with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker network inspect holist_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can run deephol with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python bazel-bin/deepmath/deephol/main --prover_options=data/configuration/prover_options.textpb --output=proof_logs.textpbs --proof_assistant_server_address=<ip of proof assistant>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify using the proof checker\n",
    "//TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "# Prover\n",
    "//TODO  \n",
    "By default, deephol will use the BFS prover defined in `prover.py`. You can use these methods to implement your own\n",
    "\n",
    "## Custom Constructor\n",
    "If your prover needs a custom `__init__()`, you can implement it here.  \n",
    "\n",
    "*note that the function in this file is called `_init_` rather than `__init__`. This is an intentional implementation detail and not a typo*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " %%writefile deepmath/deephol/jup_prover/custom/constructor.py\n",
    "\n",
    "###### your code below #####\n",
    "    \n",
    "def _init_(self, prover_options: deephol_pb2.ProverOptions, hol_wrapper,\n",
    "               action_gen: action_generator.ActionGenerator,\n",
    "               theorem_db: proof_assistant_pb2.TheoremDatabase):\n",
    "    super(NoBacktrackProver, self).__init__(\n",
    "        prover_options, hol_wrapper, theorem_db, single_goal=True)\n",
    "    self.action_gen = action_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prove One\n",
    "This is the only method that needs to be implemented. It should search the proof tree to find a single proof, and return `None` upon success, or an error message upon failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prove_one(self, tree: proof_search_tree.ProofSearchTree,\n",
    "                task: proof_assistant_pb2.ProverTask) -> Optional[Text]:\n",
    "    \"\"\"Searches for a proof via BFS.\n",
    "    Args:\n",
    "      tree: Search tree with a single goal node to be proved.\n",
    "      task: ProverTask to be performed.\n",
    "    Returns:\n",
    "      None on success and error message on failure.\n",
    "    \"\"\"\n",
    "    root = tree.nodes[0]\n",
    "    nodes_explored = 0\n",
    "    # Note that adding new node to the tree might re-enable previous nodes\n",
    "    # for tactic applications, if they were marked to be ignored by\n",
    "    # failing sibling nodes.\n",
    "    tree.cur_index = 0\n",
    "    while not self.timed_out() and not root.closed and not root.failed and (\n",
    "        nodes_explored < self.options.max_explored_nodes):\n",
    "      if tree.cur_index >= len(tree.nodes):\n",
    "        return 'BFS: All nodes are failed or ignored.'\n",
    "      node = tree.nodes[tree.cur_index]\n",
    "      tree.cur_index += 1\n",
    "      if node.ignore or node.failed or node.closed or node.processed:\n",
    "        continue\n",
    "      nodes_explored += 1\n",
    "      # Note that the following function might change tree.cur_index\n",
    "      # (if a node that was ignored suddenly becomes subgoal of a new\n",
    "      # tactic application).\n",
    "      prover_util.try_tactics(node, self.options.max_top_suggestions,\n",
    "                              self.options.min_successful_branches,\n",
    "                              self.options.max_successful_branches,\n",
    "                              task.premise_set, self.action_gen,\n",
    "                              self.prover_options.tactic_timeout_ms)\n",
    "    root_status = ' '.join([\n",
    "        p[0] for p in [('closed', root.closed), ('failed', root.failed)] if p[1]\n",
    "    ])\n",
    "    tf.logging.info('Timeout: %s root status: %s explored: %d',\n",
    "                    str(self.timed_out()), root_status, nodes_explored)\n",
    "    if self.timed_out():\n",
    "      return 'BFS: Timeout.'\n",
    "    elif root.failed:\n",
    "      return 'BFS: Root Failed.'\n",
    "    elif nodes_explored >= self.options.max_explored_nodes and not root.closed:\n",
    "      return 'BFS: Node limit reached.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selection Strategies\n",
    "\n",
    "## Attributes\n",
    "A few words about the class attributes that don't need to be implemented.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal Embedding \n",
    "\n",
    "**`_batch_goal_embedding(self, goals: List[Text]) -> BATCH_GOAL_EMB_TYPE`**  \n",
    "Compute embeddings from a list of goals   \n",
    "  \n",
    "  \n",
    "\n",
    "#### Parameters:\n",
    "-   `goals: List[Text]`\n",
    "List of goals as strings\n",
    "\n",
    "#### Return Value:\n",
    "-   `goal_embeddings: numpy.ndarray`  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile deepmath/deephol/jup_predict/custom/goal_emb.py\n",
    "\n",
    "###### your code below #####\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def _batch_goal_embedding(predictor, goals) -> BATCH_GOAL_EMB_TYPE:\n",
    "    return np.array([[goal.__hash__(), 0] for goal in goals])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theorem Embedding \n",
    "\n",
    "**` _batch_thm_embedding(self, thms: List[Text]) -> BATCH_THM_EMB_TYPE`**  \n",
    "From a list of string theorems, computes and returns their embeddings.  \n",
    "\n",
    "#### Parameters\n",
    "-   `thms: List[Text]`  \n",
    "List of theorems as strings\n",
    "\n",
    "#### Return Value\n",
    "- `theorem_embeddings: numpy.ndarray`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile deepmath/deephol/jup_predict/custom/thm_emb.py\n",
    "\n",
    "###### your code below #####\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def _batch_thm_embedding(predictor, thms):\n",
    "    \"\"\"From a list of string theorems, compute and return their embeddings.\"\"\"\n",
    "    return np.array([[thm.__hash__(), 1] for thm in thms])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proof State \n",
    "\n",
    "### `proof_state_from_search(self, node: proof_search_tree.ProofSearchNode) -> ProofState:`\n",
    "Convert from `proof_search_tree.ProofSearchNode` to proof state.\n",
    "\n",
    "#### Parameters\n",
    "-   `node: proof_search_tree.ProofSearchNode`\n",
    "\n",
    "#### Return Value\n",
    "-   `proof_state: predictions.ProofState`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile deepmath/deephol/jup_predict/custom/st_search.py\n",
    "\n",
    "###### your code below #####\n",
    "\n",
    "from deepmath.deephol import predictions\n",
    "\n",
    "def _proof_state_from_search(predictor, node):\n",
    "    return predictions.ProofState(goal='goal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proof State Embedding \n",
    "\n",
    "### `proof_state_embedding(self, state: ProofState) -> EmbProofState:`\n",
    "From a proof state, computes and returns embeddings of each component.  \n",
    "\n",
    "#### Parameters\n",
    "-   `state: predictions.ProofState`\n",
    "\n",
    "#### Return Value\n",
    "-   `proof_state_embedding: predictions.EmbProofState`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile deepmath/deephol/jup_predict/custom/st_emb.py\n",
    "\n",
    "###### your code below #####\n",
    "\n",
    "from deepmath.deephol import predictions\n",
    "\n",
    "def _proof_state_embedding(predictor, state):\n",
    "    return predictions.EmbProofState(*[[x.__hash__(), 2] for x in state])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proof State Encoding \n",
    "\n",
    "### `proof_state_encoding(self, state_emb: EmbProofState) -> STATE_ENC_TYPE:`\n",
    "From an embedding of a proof state, computes and returns its encoding.\n",
    "\n",
    "#### Parameters\n",
    "-   `state_emb: predictions.EmbProofState`\n",
    "\n",
    "#### Return Value\n",
    "-   `state_encoding: numpy.ndarray`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile deepmath/deephol/jup_predict/custom/st_enc.py\n",
    "\n",
    "###### your code below #####\n",
    "\n",
    "def _proof_state_encoding(predictor, state_emb):\n",
    "    return state_emb.goal_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tactic Selection\n",
    "\n",
    "### `_batch_tactic_scores(self, state_encodings: List[STATE_ENC_TYPE]) -> np.ndarray:`\n",
    "Predicts tactic probabilities for a batch of goals.  \n",
    "\n",
    "#### Parameters\n",
    "-   `state_encodings: List[numpy.ndarray[TODO]]`\n",
    "\n",
    "#### Return Value\n",
    "-   `tactic_scores: numpy.ndarray[batch_size, num_tactics]`  \n",
    "\n",
    "2D array of dimension \\[batch_size, num_tactics\\] representing tactic probabilities. Batch size is the length of `goal_embeddings`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting deepmath/deephol/jup_predict/custom/tac_sc.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile deepmath/deephol/jup_predict/custom/tac_sc.py\n",
    "\n",
    "###### your code below #####\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def _batch_tactic_scores(predictor, goal_embeddings):\n",
    "    num_tactics = 41\n",
    "    return np.array([[np.sum(emb)] + [.0]*40 for emb in goal_embeddings]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Premise Selection\n",
    "\n",
    "### ` _batch_thm_scores(self, state_encodings: List[STATE_ENC_TYPE], thm_embeddings: BATCH_THM_EMB_TYPE, tactic_id: Optional[int] = None) -> List[float]:` \n",
    "Predict relevance scores for goal, theorem pairs.  \n",
    "\n",
    "#### Parameters\n",
    "-   `state_encodings: List[numpy.ndarray]`\n",
    "-   `theorem_embeddings: numpy.ndarray`\n",
    "-   `tactic_id: int` (optional)\n",
    "\n",
    "#### Return Value\n",
    "-   `tactic_scores: List[float]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile deepmath/deephol/jup_predict/custom/tac_sc.py\n",
    "\n",
    "###### your code below #####\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def _batch_thm_scores(predictor, goal_embeddings, thm_embeddings, tactic_id=None):\n",
    "    if tactic_id is not None:\n",
    "        c = 3.0 * float(tactic_id)\n",
    "    else:\n",
    "        c = 2.0\n",
    "    return np.array([\n",
    "          np.sum(e1) + c * np.sum(e2)\n",
    "          for (e1, e2) in zip(goal_embeddings, thm_embeddings)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run DeepHol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash run.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Related Work\n",
    "\n",
    "## Papers\n",
    "* [HOList: An Environment for Machine Learning of Higher-Order Theorem Proving](https://arxiv.org/pdf/1904.03241.pdf)  \n",
    "* [Learning to Prove Theorems via Interacting with Proof Assistants](https://arxiv.org/pdf/1905.09381.pdf)  \n",
    "\n",
    "## Resources \n",
    "* [HOList Site](https://sites.google.com/view/holist/home)\n",
    "* [Deepmath Repository](https://github.com/tensorflow/deepmath) \n",
    "* [HOL-Light Repository](https://github.com/brain-research/hol-light)\n",
    "* [CoqGym](https://github.com/princeton-vl/CoqGym)\n",
    "\n",
    "\n",
    "\n",
    "# About This Project\n",
    "This tutorial was made as part of an undergraduate research project at University of Central Florida, supervised by Dr. Sumit Jha.\n",
    "\n",
    "# Contact\n",
    "* Aaron Hadley: aahadley1@gmail.com\n",
    "* Tyler McFadden: neruelin@gmail.com\n",
    "* Jordan Starkey: jordanstarkey95@gmail.com\n",
    "* Sumit Jha: Sumit.Jha@ucf.edu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
